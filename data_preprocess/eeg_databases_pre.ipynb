{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Databases Perprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X: 数据\n",
    "- y: 标签\n",
    "- subjects（受试者）: 确保同一个受试者的数据不会同时出现在训练集和测试集中，以防止模型记住特定受试者的特征，而不是学习到普遍的模式。\n",
    "- trials（试验编号）: 受试者的试验编号, 用于标识同一个受试者在不同时间点或不同条件下进行的多次试验\n",
    "- sessions（会话）: 同一个受试者可能在不同的会话中表现不同。将不同会话的数据分开，可以评估模型在同一个受试者不同时间点的数据上的表现。\n",
    "\n",
    "在机器学习和深度学习中，数据通常被分割成训练集、验证集和测试集。这些数据集分别用于训练模型、调参和验证模型、以及最终评估模型性能。以下是各个数据集的含义：\n",
    "\n",
    "1. 训练集 (Training Set):\n",
    "\n",
    "    - X_train: 训练集的特征数据，输入数据集。\n",
    "    - Y_train: 训练集的标签数据，目标输出。\n",
    "    - S_train: 训练集的受试者ID，表示每个样本对应的受试者。\n",
    "    - P_train: 训练集的试验阶段或试次，表示每个样本对应的实验阶段或试次。\n",
    "\n",
    "2. 验证集 (Validation Set):\n",
    "\n",
    "    - X_val: 验证集的特征数据，用于调参和验证模型。\n",
    "    - Y_val: 验证集的标签数据。\n",
    "    - S_val: 验证集的受试者ID。\n",
    "    - P_val: 验证集的试验阶段或试次。\n",
    "\n",
    "3. 测试集 (Test Set):\n",
    "\n",
    "    - X_test: 测试集的特征数据，用于最终评估模型性能。\n",
    "    - Y_test: 测试集的标签数据。\n",
    "    - S_test: 测试集的受试者ID。\n",
    "    - P_test: 测试集的试验阶段或试次。\n",
    "\n",
    "各个数据集的具体含义如下：\n",
    "\n",
    "- X_train, X_val, X_test: 这些是特征矩阵（例如EEG数据），每一行表示一个样本，每一列表示一个特征。\n",
    "- Y_train, Y_val, Y_test: 这些是标签向量，表示每个样本对应的类别或目标值。\n",
    "- S_train, S_val, S_test: 这些是受试者ID，表示每个样本对应的受试者编号，有助于在跨受试者的实验中进行分析。\n",
    "- P_train, P_val, P_test: 这些是试验阶段或试次，表示每个样本对应的实验阶段或试次编号，有助于在跨试次的实验中进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAP数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从DEAP数据集中读取的数据包含脑电图（EEG）信号和其他生理信号，这些信号用于情绪识别研究。具体来说，DEAP数据集包括以下内容：\n",
    "\n",
    "1. **EEG信号**：\n",
    "   - 记录了32个电极位置的EEG数据，每个电极采样率为128 Hz。\n",
    "   - 每个试验持续63秒，其中前3秒是基线（休息状态），接下来的60秒是观看视频的时间。\n",
    "   - 数据已预处理，包括去噪和滤波（通常在4-45 Hz之间）。\n",
    "2. **其他生理信号**：\n",
    "   - 皮电反应（GSR）\n",
    "   - 血容量脉搏（BVP）\n",
    "   - 心电图（ECG）\n",
    "   - 体温（TEMP）\n",
    "   - 呼吸频率（RESP）\n",
    "3. **情绪标签**：\n",
    "   - 被试者在观看每个视频后对情绪进行了评分，评分维度包括：\n",
    "     - Valence（情绪价度）：1到9的评分，表示从非常负面到非常正面。\n",
    "     - Arousal（情绪唤醒度）：1到9的评分，表示从非常平静到非常激动。\n",
    "     - Dominance（支配度）：1到9的评分，表示情绪的控制感。\n",
    "     - Liking（喜欢度）：1到9的评分，表示对视频的喜欢程度。\n",
    "\n",
    "### 读取和处理数据的示例\n",
    "\n",
    "以下是一个示例代码，展示如何从DEAP数据集中读取这些数据：\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# 定义数据路径\n",
    "data_path = 'DEAP/data_preprocessed_python'\n",
    "\n",
    "# 定义加载和处理数据的函数\n",
    "def load_deap_data(data_path):\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith('.dat')]\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f, encoding='latin1')\n",
    "            all_data.append(data['data'])  # EEG和其他生理信号\n",
    "            all_labels.append(data['labels'])  # 情绪标签\n",
    "\n",
    "    return np.array(all_data), np.array(all_labels)\n",
    "\n",
    "# 读取数据\n",
    "x_data, y_data = load_deap_data(data_path)\n",
    "\n",
    "# 查看数据形状\n",
    "print('EEG和生理信号数据形状:', x_data.shape)\n",
    "print('情绪标签数据形状:', y_data.shape)\n",
    "\n",
    "```\n",
    "\n",
    "### 数据的形状和内容\n",
    "\n",
    "- **EEG和生理信号数据形状**：形状为 `(num_subjects, num_trials, num_channels, num_samples)`，例如 `(32, 40, 40, 8064)`。\n",
    "  - `num_subjects`是参与实验的被试者数量（32个）\n",
    "  - `num_trials`是每个被试者观看的视频数量（40个）\n",
    "  - `num_channels`是EEG和其他生理信号的通道数量（32个EEG通道和8个其他生理信号通道，总计40个）\n",
    "  - `num_samples`是每个试验的采样点数量（8064个，63秒 × 128 Hz）。\n",
    "\n",
    "- **情绪标签数据形状**：形状为 `(num_subjects, num_trials, num_labels)`，例如 `(32, 40, 4)`。\n",
    "  - `um_subjects`是参与DEAP实验的被试者数量。DEAP数据集包含32个被试者，每个被试者分别参与了实验（32个）\n",
    "  - `num_trials`是每个被试者观看的视频数量。每个被试者观看了40个不同的1分钟视频片段，并在观看后对每个视频进行评分（40个）\n",
    "  - `num_labels`是每个试验的情绪标签数量。在DEAP数据集中，每个视频试验有4个标签（4个）\n",
    "    - Valence（情绪价度）：表示情绪的正负面，从1（非常负面）到9（非常正面）。\n",
    "    - Arousal（情绪唤醒度）：表示情绪的激动程度，从1（非常平静）到9（非常激动）。\n",
    "    - Dominance（支配度）：表示被试者对情绪的控制感，从1（无控制感）到9（完全控制感）。\n",
    "    - Liking（喜欢度）：表示被试者对视频的喜欢程度，从1（非常不喜欢）到9（非常喜欢）。\n",
    "\n",
    "> ```python\n",
    "> channel_names = [\n",
    ">  'FP1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2',  # EEG channels\n",
    ">  'GSR', 'BVP', 'ECG', 'TEMP', 'RESP', 'EOG_L', 'EOG_R', 'EMG'  # Other physiological signals\n",
    "> ]\n",
    "> ```\n",
    ">\n",
    "> 在DEAP数据集中，除了32个EEG（脑电图）通道外，还有8个其他生理信号通道。这些通道用于记录各种生理参数，以便更全面地理解情绪反应。具体来说，这8个通道是：\n",
    ">\n",
    "> 1. **皮肤电反应（Galvanic Skin Response, GSR）**：测量皮肤的电导率，反映汗腺活动，通常用于评估情绪唤醒度。\n",
    "> 2. **血容量脉搏（Blood Volume Pulse, BVP）**：通过光电容积描记（Photoplethysmography, PPG）技术测量血液流动变化，常用于评估心率。\n",
    "> 3. **心电图（Electrocardiogram, ECG）**：记录心脏的电活动，提供心率变异性等信息。\n",
    "> 4. **体温（Temperature, TEMP）**：测量皮肤温度，反映生理激活状态。\n",
    "> 5. **呼吸频率（Respiration, RESP）**：记录呼吸速率和深度变化。\n",
    "> 6. **左眼眼电图（Electrooculogram, EOG_L）**：记录左眼周围的电活动，用于跟踪眼动和眨眼。\n",
    "> 7. **右眼眼电图（Electrooculogram, EOG_R）**：记录右眼周围的电活动，用于跟踪眼动和眨眼。\n",
    "> 8. **肌电图（Electromyogram, EMG）**：记录肌肉活动，通常放置在面部肌肉上以捕捉面部表情的变化。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主要代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample\n",
    "from tqdm import tqdm, trange\n",
    "import warnings\n",
    "import pickle\n",
    "from scipy.signal import butter, filtfilt, sosfilt, sosfreqz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For preprocessing\n",
    "deap_config = {\n",
    "    \"dataset_name\": \"deap_t\",\n",
    "    \"databases_root_directory\": r\"E:/Databases/RawData/DEAP/data_preprocessed_python\",\n",
    "    \"databases_out_directory\": r\"E:/Databases/OutData/DEAP/\",\n",
    "    \"sampling_rate\": 128,\n",
    "    \"resampling_rate\": 128,\n",
    "    \"channel_names\": ['FP1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3', 'O1', 'OZ', 'PZ', 'FP2', 'AF4', 'FZ', 'F4', 'F8', 'FC6', 'FC2', 'CZ', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2'],\n",
    "    \"channels_to_use\": ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4'],\n",
    "    \"baseline_removal_window\": 3,\n",
    "    \"cutoff_frequencies\": [4,40],\n",
    "    \"seconds_to_use\": 60,\n",
    "    \"window_size\": 2,\n",
    "    \"window_overlap\": 0,\n",
    "    \"progress_bar\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信号处理类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalProcessor:\n",
    "    def __init__(self, fs=128):\n",
    "        self.fs = fs\n",
    "\n",
    "    def plot_frequency_spectrum(self, signal, fs=None, title='Frequency Spectrum'):\n",
    "        \"\"\"\n",
    "        计算并绘制一维数组的频谱图。\n",
    "        参数：\n",
    "        signal (ndarray): 输入的一维数组。\n",
    "        fs (int): 采样频率。\n",
    "        返回：\n",
    "        None\n",
    "        \"\"\"\n",
    "        if fs is None:\n",
    "            fs = self.fs\n",
    "        # 计算傅里叶变换\n",
    "        spectrum = np.fft.fft(signal)\n",
    "        # 获取频率分量\n",
    "        freqs = np.fft.fftfreq(len(signal), 1/fs)\n",
    "        # 只取前半部分频率，因为频谱是对称的\n",
    "        freqs = freqs[:len(freqs)//2]\n",
    "        spectrum = np.abs(spectrum[:len(spectrum)//2])\n",
    "        \n",
    "        # 绘制频谱图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs, spectrum)\n",
    "        plt.title(title)\n",
    "        plt.X_cp_cp_cp_cp_cplabel('Frequency (Hz)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.show()\n",
    "\n",
    "        return freqs, spectrum\n",
    "\n",
    "    def highpass_filter(self, signal, fs=None, cutoff=4, order=5):\n",
    "        \"\"\"\n",
    "        对信号进行高通滤波。\n",
    "        参数：\n",
    "        signal (ndarray): 输入信号。\n",
    "        cutoff (float): 截止频率。\n",
    "        fs (int): 采样频率。\n",
    "        order (int): 滤波器阶数。\n",
    "        返回：\n",
    "        ndarray: 高通滤波后的信号。\n",
    "        \"\"\"\n",
    "        if fs is None:\n",
    "            fs = self.fs\n",
    "        nyquist = 0.5 * fs  # 计算奈奎斯特频率\n",
    "        normal_cutoff = cutoff / nyquist  # 将截止频率归一化到[0, 1]之间\n",
    "        b, a = butter(order, normal_cutoff, btype='high', analog=False)  # 设计高通Butterworth滤波器\n",
    "        filtered_signal = filtfilt(b, a, signal)  # 使用filtfilt函数应用滤波器，避免相位失真\n",
    "        return filtered_signal  # 返回滤波后的信号\n",
    "    \n",
    "    def lowpass_filter(self, signal, fs=None, cutoff=40, order=5):\n",
    "        \"\"\"\n",
    "        对信号进行低通滤波。\n",
    "        参数：\n",
    "        signal (ndarray): 输入信号。\n",
    "        cutoff (float): 截止频率。\n",
    "        fs (int): 采样频率。\n",
    "        order (int): 滤波器阶数。\n",
    "        返回：\n",
    "        ndarray: 低通滤波后的信号。\n",
    "        \"\"\"\n",
    "        if fs is None:\n",
    "            fs = self.fs\n",
    "        nyquist = 0.5 * fs  # 计算奈奎斯特频率\n",
    "        normal_cutoff = cutoff / nyquist  # 将截止频率归一化到[0, 1]之间\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)  # 设计低通Butterworth滤波器\n",
    "        filtered_signal = filtfilt(b, a, signal)  # 使用filtfilt函数应用滤波器，避免相位失真\n",
    "        return filtered_signal  # 返回滤波后的信号\n",
    "    \n",
    "    def bandpass_filter(self, signal, fs=None, lowcut=40, highcut=4, order=5):\n",
    "        \"\"\"\n",
    "        对信号进行带通滤波。\n",
    "        参数：\n",
    "        signal (ndarray): 输入信号。\n",
    "        lowcut (float): 低截止频率。\n",
    "        highcut (float): 高截止频率。\n",
    "        fs (int): 采样频率。\n",
    "        order (int): 滤波器阶数。\n",
    "        返回：\n",
    "        ndarray: 带通滤波后的信号。\n",
    "        \"\"\"\n",
    "        if fs is None:\n",
    "            fs = self.fs\n",
    "        nyquist = 0.5 * fs  # 计算奈奎斯特频率\n",
    "        low = lowcut / nyquist  # 将低截止频率归一化到[0, 1]之间\n",
    "        high = highcut / nyquist  # 将高截止频率归一化到[0, 1]之间\n",
    "        b, a = butter(order, [low, high], btype='band')  # 设计带通Butterworth滤波器\n",
    "        filtered_signal = filtfilt(b, a, signal)  # 使用filtfilt函数应用滤波器，避免相位失真\n",
    "        return filtered_signal  # 返回滤波后的信号\n",
    "    \n",
    "    def notch_filter(self, signal, fs=None, cutoff=50, quality_factor=30):\n",
    "        \"\"\"\n",
    "        对信号进行陷波滤波。\n",
    "        参数：\n",
    "        signal (ndarray): 输入信号。\n",
    "        cutoff (float): 陷波频率。\n",
    "        fs (int): 采样频率。\n",
    "        quality_factor (float): 品质因数。\n",
    "        返回：\n",
    "        ndarray: 陷波滤波后的信号。\n",
    "        \"\"\"\n",
    "        if fs is None:\n",
    "            fs = self.fs\n",
    "        nyquist = 0.5 * fs  # 计算奈奎斯特频率\n",
    "        normal_cutoff = cutoff / nyquist  # 将陷波频率归一化到[0, 1]之间\n",
    "        b, a = butter(2, [normal_cutoff - normal_cutoff / quality_factor, \n",
    "                        normal_cutoff + normal_cutoff / quality_factor], btype='bandstop')  # 设计带阻Butterworth滤波器\n",
    "        filtered_signal = filtfilt(b, a, signal)  # 使用filtfilt函数应用滤波器，避免相位失真\n",
    "        return filtered_signal  # 返回滤波后的信号\n",
    "    \n",
    "    def baseline_adjustments(self, signal):\n",
    "        \"\"\"\n",
    "        基线调整\n",
    "        参数：\n",
    "        signal (ndarray): 输入信号。\n",
    "        返回：\n",
    "        ndarray: 调整后的信号。\n",
    "        \"\"\"\n",
    "        base_line = signal.sum(0) / len(signal)\n",
    "        signal = signal - base_line\n",
    "        return signal\n",
    "    \n",
    "    def plot_signal_and_spectrum(self, signal, fs=None, suptitle='Signal and Spectrum'):\n",
    "        \"\"\"\n",
    "        绘制信号和频谱图。\n",
    "        \n",
    "        参数：\n",
    "        signal (ndarray): 输入的一维数组。\n",
    "        fs (int): 采样频率。如果未提供，使用默认的 self.fs。\n",
    "        suptitle (str): 图的总标题。\n",
    "        \n",
    "        返回：\n",
    "        None\n",
    "        \"\"\"\n",
    "        if fs is None:\n",
    "            fs = self.fs\n",
    "\n",
    "        # 计算傅里叶变换\n",
    "        spectrum = np.fft.fft(signal)\n",
    "        # 获取频率分量\n",
    "        freqs = np.fft.fftfreq(len(signal), 1/fs)\n",
    "        # 只取前半部分频率，因为频谱是对称的\n",
    "        freqs = freqs[:len(freqs)//2]\n",
    "        spectrum = np.abs(spectrum[:len(spectrum)//2])\n",
    "        # 创建图形\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        # 绘制信号\n",
    "        axs[0].plot(signal)\n",
    "        axs[0].set_title('Signal')\n",
    "        axs[0].set_xlabel('Time')\n",
    "        axs[0].set_ylabel('Amplitude')\n",
    "        # 绘制频谱图\n",
    "        axs[1].plot(freqs, spectrum)\n",
    "        axs[1].set_title('Spectrum')\n",
    "        axs[1].set_xlabel('Frequency (Hz)')\n",
    "        axs[1].set_ylabel('Amplitude')\n",
    "        # 添加总标题\n",
    "        plt.suptitle(suptitle)\n",
    "        # 调整布局\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])  # 调整布局以确保标题不重叠\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabasesPreprocessing(SignalProcessor):\n",
    "    def __init__(self, config):\n",
    "        self.dataset_name = config[\"dataset_name\"]\n",
    "        self.databases_root_directory = config[\"databases_root_directory\"]\n",
    "        self.databases_out_directory = config[\"databases_out_directory\"]\n",
    "        self.sampling_rate = config[\"sampling_rate\"]\n",
    "        self.resampling_rate = config[\"resampling_rate\"]\n",
    "        self.channel_names = config[\"channel_names\"]\n",
    "        self.channels_to_use = config[\"channels_to_use\"]\n",
    "        self.baseline_removal_window = config[\"baseline_removal_window\"]\n",
    "        self.cutoff_frequencies = config[\"cutoff_frequencies\"]\n",
    "        self.seconds_to_use = config[\"seconds_to_use\"]\n",
    "        self.window_size = config[\"window_size\"]\n",
    "        self.window_overlap = config[\"window_overlap\"]\n",
    "        self.progress_bar = config[\"progress_bar\"]\n",
    "        self.convert_labels_to_nnp = False\n",
    "        super().__init__(fs=self.sampling_rate)\n",
    "\n",
    "    def load_deap_data(self, data_path, rm_baseline=True):\n",
    "        \"\"\"\n",
    "        加载DEAP数据集\n",
    "        参数:\n",
    "        data_path (str): 存储DEAP数据集的目录路径\n",
    "        rm_baseline (bool): 是否移除前3s休息时的基线数据\n",
    "        返回: \n",
    "        x_data, y_labels, subjects, trials, sessions = load_deap_data(data_path=data_path)\n",
    "        tuple: 包含所有被试的EEG和其他生理信号数据，以及对应的情绪标签数据。\n",
    "            x_data_32 (ndarray): 移除基线前形状为 (1280, 32, 8064) 的EEG数据。 移除基线后形状为 (1280, 32, 7680) 的EEG数据。\n",
    "            y_data (ndarray): 形状为 (1280, 4) 的情绪标签数据。\n",
    "        \"\"\"\n",
    "        # 获取目录中所有以.dat结尾的文件名\n",
    "        files = [f for f in os.listdir(data_path) if f.endswith('.dat')]\n",
    "        # 初始化存储所有数据和标签的列表\n",
    "        raw_data = []  # 形状为 (num_subjects, num_trials, num_channels, num_samples)\n",
    "        raw_labels = []  # 形状为 (num_subjects, num_trials, num_labels)\n",
    "        subjects = []  # 存储每个试验的受试者编号\n",
    "        trials = []  # 存储每个受试者的每次试验编号\n",
    "        sessions = []  # 存储每个试验的会话编号\n",
    "        # 是否显示进度条\n",
    "        if self.progress_bar:\n",
    "            files_iter = tqdm(files, desc=\"Loading DEAP data\")\n",
    "        else:\n",
    "            files_iter = files\n",
    "        # 遍历每个文件\n",
    "        for file in files_iter:\n",
    "            # 获取每个文件的完整路径\n",
    "            file_path = os.path.join(data_path, file)\n",
    "            # 打开并读取文件中的数据\n",
    "            with open(file_path, 'rb') as f:\n",
    "                # 使用latin1编码读取文件\n",
    "                data = pickle.load(f, encoding='latin1')\n",
    "                # 提取EEG和其他生理信号数据，并添加到 raw_data 列表中\n",
    "                raw_data.append(data['data'])\n",
    "                # 提取情绪标签数据，并添加到 raw_labels 列表中\n",
    "                raw_labels.append(data['labels'])\n",
    "                # # 添加受试者和试验信息\n",
    "                subject_id = int(file[1:3])  # 提取受试者编号\n",
    "                subjects.extend([subject_id] * 40)  # 每个受试者有 40 次试验\n",
    "                trials.extend(range(1, 41))  # 每个受试者的试验编号从 1 到 40\n",
    "                sessions.extend([1] * 40)  # 假设每个受试者只有一个会话\n",
    "        # 将 raw_data 的形状从 (32, 40, 40, 8064) 改为 (1280, 40, 8064)\n",
    "        x_data = np.array(raw_data).reshape(32*40, 40, 8064)\n",
    "        # 选择前 32 个通道并去除前3s准备时间变为 (1280, 32, 7680)\n",
    "        if rm_baseline:\n",
    "            x_data_32 = x_data[:, :32, self.baseline_removal_window*self.sampling_rate:]\n",
    "        # 将 raw_labels 的形状从 (32, 40, 4) 改为 (1280, 4)\n",
    "        y_labels = np.array(raw_labels).reshape(32*40, 4)\n",
    "        # 将结果转换为NumPy数组并返回\n",
    "        return np.array(x_data_32), np.array(y_labels), np.array(subjects), np.array(trials), np.array(sessions)\n",
    "    \n",
    "    def deap_filter(self, X):\n",
    "        # 复制输入信号，以保护原始数据\n",
    "        X_cp = np.copy(X)\n",
    "        if self.progress_bar:\n",
    "            ep_id = trange(X_cp.shape[0], desc='Baseline adjustments and filter')\n",
    "        else:\n",
    "            ep_id = range(X_cp.shape[0])\n",
    "        for experiment_id in ep_id:\n",
    "            for channel_id in range(X_cp.shape[1]):\n",
    "                # 基线调整\n",
    "                X_cp[experiment_id, channel_id, :] = self.baseline_adjustments(signal=X_cp[experiment_id, channel_id, :])\n",
    "                # 滤波\n",
    "                X_cp[experiment_id, channel_id, :] = self.highpass_filter(signal=X_cp[experiment_id, channel_id, :], cutoff=self.cutoff_frequencies[0])\n",
    "                X_cp[experiment_id, channel_id, :] = self.lowpass_filter(signal=X_cp[experiment_id, channel_id, :], cutoff=self.cutoff_frequencies[1])\n",
    "        \n",
    "        # 重采样\n",
    "        if not (self.resampling_rate == self.sampling_rate) and not (self.resampling_rate == 0):\n",
    "            X_cp = self.resampling(X=X_cp, sampling_rate=self.sampling_rate, resampling_rate=self.resampling_rate)\n",
    "        # 选择合适的通道\n",
    "        X_cp = self.select_channels(X=X_cp)\n",
    "        \n",
    "\n",
    "        return X_cp\n",
    "    \n",
    "    def resampling(self, X, sampling_rate, resampling_rate):\n",
    "        \"\"\"\n",
    "        对信号进行重采样。\n",
    "        参数：\n",
    "        X (ndarray): 输入信号，形状为 (num_subjects, num_trials, num_samples)。\n",
    "        sampling_rate (int): 原始采样率。\n",
    "        resampling_rate (int): 目标采样率。\n",
    "        返回：\n",
    "        ndarray: 重采样后的信号。\n",
    "        \"\"\"\n",
    "        # 复制输入信号，以保护原始数据\n",
    "        X_cp = np.copy(X)\n",
    "        # 检查是否需要重采样（目标采样率不为零且不同于原始采样率）\n",
    "        if not(resampling_rate == 0) and not(resampling_rate == sampling_rate):\n",
    "            # 计算重采样后的新长度\n",
    "            new_length = int(X_cp.shape[2] / sampling_rate * resampling_rate)\n",
    "            # 初始化重采样后的数组，形状为 (num_subjects, num_trials, new_length)\n",
    "            X_resampled = np.zeros((X_cp.shape[0], X_cp.shape[1], new_length))\n",
    "            # 判断是否需要显示进度条\n",
    "            if self.progress_bar:\n",
    "                ep_id = trange(X_cp.shape[0], desc='Downsampling')\n",
    "            else:\n",
    "                ep_id = range(X_cp.shape[0])\n",
    "            # 遍历每个实验\n",
    "            for experiment_id in ep_id:\n",
    "                # 遍历每个通道\n",
    "                for channel_id in range(X_cp.shape[1]):\n",
    "                    # 对每个通道的数据进行重采样\n",
    "                    X_resampled[experiment_id, channel_id, :] = resample(X_cp[experiment_id, channel_id, :], new_length)\n",
    "            # 更新复制的数据为重采样后的数据\n",
    "            X_cp = X_resampled\n",
    "        # 返回重采样后的信号\n",
    "        return X_cp\n",
    "    \n",
    "    def select_channels(self, X):\n",
    "        \"\"\"\n",
    "        选择特定的通道。\n",
    "        \n",
    "        参数：\n",
    "        X (ndarray): 输入信号，形状为 (num_subjects, num_channels, num_samples)。\n",
    "        \n",
    "        返回：\n",
    "        ndarray: 选择通道后的信号，形状为 (num_subjects, len(self.channels_to_use), num_samples)。\n",
    "        \"\"\"\n",
    "        # 复制输入信号，以保护原始数据\n",
    "        X_cp = np.copy(X)\n",
    "        # 初始化通道索引列表\n",
    "        channel_index_list = list()\n",
    "        # 查找需要使用的通道索引\n",
    "        for i in range(len(self.channels_to_use)):\n",
    "            # 如果通道在实际通道名称列表中，添加其索引到通道索引列表中\n",
    "            if self.channels_to_use[i] in self.channel_names:\n",
    "                channel_index_list.append(self.channel_names.index(self.channels_to_use[i]))\n",
    "            else:\n",
    "                # 如果通道不在实际通道名称列表中，发出警告\n",
    "                warnings.warn(' Channel ' + self.channels_to_use[i] + ' could not be found in the list of actual channels')\n",
    "        # 初始化选择通道后的数组，形状为 (num_subjects, len(self.channels_to_use), num_samples)\n",
    "        X_selected_channels = np.zeros((X_cp.shape[0], len(self.channels_to_use), X_cp.shape[2]))\n",
    "        # 判断是否需要显示进度条\n",
    "        if self.progress_bar:\n",
    "            channel_index_list_en = tqdm(enumerate(channel_index_list), desc=\"Select channels\")\n",
    "        else:\n",
    "            channel_index_list_en = enumerate(channel_index_list)\n",
    "        # 遍历每个通道及其索引，将对应的通道数据复制到选择后的数组中\n",
    "        for channel, channel_index in channel_index_list_en:\n",
    "            X_selected_channels[:, channel, :] = X_cp[:, channel_index, :]\n",
    "        # 更新复制的数据为选择通道后的数据\n",
    "        X_cp = X_selected_channels\n",
    "        # 返回选择通道后的信号\n",
    "        return X_cp\n",
    "    \n",
    "    def deap_label_conversion(self, X, y, subjects, trials, sessions, convert_labels_to_nnp=False, plot_en=False):\n",
    "        \"\"\"\n",
    "        转换 DEAP 数据集的标签，并对数据进行窗口化处理。\n",
    "        参数：\n",
    "        - X: 输入的信号数据。\n",
    "        - y: 输入的标签数据。\n",
    "        - subjects: 受试者编号。\n",
    "        - trials: 试验编号。\n",
    "        - sessions: 会话编号。\n",
    "        - convert_labels_to_nnp: 是否转换为 NNP 标签。\n",
    "        - plot_en: 是否启用绘图。\n",
    "        返回：\n",
    "        - X_cp: 窗口化处理后的信号数据。\n",
    "        - y_cp: 转换后的标签数据。\n",
    "        - subjects: 处理后的受试者编号。\n",
    "        - trials: 处理后的试验编号。\n",
    "        - sessions: 处理后的会话编号。\n",
    "        \"\"\"\n",
    "        # 复制输入信号, 保护原始数据\n",
    "        X_cp = np.copy(X)\n",
    "        y_cp = np.copy(y)\n",
    "        # 计算每个窗口的点数和每个窗口的重叠点数\n",
    "        num_points_per_window = self.window_size * self.resampling_rate\n",
    "        num_points_overlap = self.window_overlap * self.resampling_rate\n",
    "        # 计算窗口滑动的步长\n",
    "        stride = num_points_per_window - num_points_overlap\n",
    "        # 初始化起始和结束索引列表\n",
    "        start_index = [0]\n",
    "        end_index = [num_points_per_window]\n",
    "        # 初始化每个实验的窗口数\n",
    "        num_windows_per_exp = 1\n",
    "        # 计算每个实验的窗口数以及相应的起始和结束索引\n",
    "        while(end_index[-1] + stride <= X_cp.shape[2]):\n",
    "            num_windows_per_exp += 1\n",
    "            start_index.append(start_index[-1] + stride)\n",
    "            end_index.append(end_index[-1] + stride)\n",
    "        # 初始化切割后的数据数组\n",
    "        X_cut = np.zeros((num_windows_per_exp * X_cp.shape[0], X_cp.shape[1], num_points_per_window))\n",
    "        y_cut = np.zeros((num_windows_per_exp * X_cp.shape[0], 4))\n",
    "        subjects_cut = np.zeros(num_windows_per_exp * X_cp.shape[0])\n",
    "        trials_cut = np.zeros(num_windows_per_exp * X_cp.shape[0])\n",
    "        sessions_cut = np.zeros(num_windows_per_exp * X_cp.shape[0])\n",
    "        # 判断是否需要显示进度条\n",
    "        if self.progress_bar:\n",
    "            exp_id_range = trange(X_cp.shape[0], desc=\"Cutting data\")\n",
    "        else:\n",
    "            exp_id_range = range(X_cp.shape[0])\n",
    "        # 遍历每个实验\n",
    "        for exp_id in exp_id_range:\n",
    "            # 遍历每个窗口\n",
    "            for window_id in range(len(start_index)):\n",
    "                # 根据窗口的起始和结束索引切割数据\n",
    "                X_cut[exp_id * num_windows_per_exp + window_id, :, :] = X_cp[exp_id, :, start_index[window_id]:end_index[window_id]]\n",
    "                # 复制标签、会话、受试者和试验信息\n",
    "                y_cut[exp_id * num_windows_per_exp + window_id, :] = y_cp[exp_id, :]\n",
    "                subjects_cut[exp_id * num_windows_per_exp + window_id] = subjects[exp_id]\n",
    "                trials_cut[exp_id * num_windows_per_exp + window_id] = trials[exp_id]\n",
    "                sessions_cut[exp_id * num_windows_per_exp + window_id] = sessions[exp_id]\n",
    "        # 更新原始数据为切割后的数据\n",
    "        X_cp = X_cut\n",
    "        y_cp = y_cut\n",
    "        subjects = subjects_cut\n",
    "        trials = trials_cut\n",
    "        sessions = sessions_cut\n",
    "        # 创建 MinMaxScaler 对象，用于将数据缩放到 [-1, 1] 范围\n",
    "        scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "        # 将情绪价度(愉快度)标签缩放到 [-1, 1] 范围\n",
    "        valence = scaler.fit_transform(y_cp[:,0].reshape(-1,1))\n",
    "        # 将唤醒度标签缩放到 [-1, 1] 范围\n",
    "        arousal = scaler.fit_transform(y_cp[:,1].reshape(-1,1))\n",
    "        # 将缩放后的愉快度和唤醒度标签按列连接成一个新的数据数组\n",
    "        datapoints = np.concatenate((valence, arousal), axis=1)\n",
    "        # 使用 KMeans 对数据进行聚类，指定聚类数量为 4，随机种子为 7\n",
    "        kmeans = KMeans(n_clusters=4, random_state=7, n_init=10).fit(datapoints)\n",
    "        # 对聚类中心点按与四个角（右下角、左下角、左上角、右上角）的距离进行排序\n",
    "        # 并分别对应悲伤 (sad)、恐惧 (fear)、中性 (neutral)、快乐 (happy) 标签\n",
    "        sad_label, fear_label, neutral_label, happy_label = self.sort_centeroids(centeroids=kmeans.cluster_centers_)\n",
    "        if plot_en:\n",
    "            # 绘制愉快度（Valence）和唤醒度（Arousal）的散点图，并使用 KMeans 聚类的标签进行着色\n",
    "            plt.scatter(valence, arousal, c=kmeans.labels_, edgecolors='none')\n",
    "            plt.xlabel('Valence')  # 设置 x 轴标签\n",
    "            plt.ylabel('Arousal')  # 设置 y 轴标签\n",
    "            plt.title('DEAP - NNP Label via K-Means')  # 设置图表标题\n",
    "            plt.show()  # 显示图表\n",
    "        # 找到每个情绪类别对应的数据点索引\n",
    "        idx_sad = np.where(kmeans.labels_ == sad_label)  # 找到悲伤类标签的数据点索引\n",
    "        idx_fear = np.where(kmeans.labels_ == fear_label)  # 找到恐惧类标签的数据点索引\n",
    "        idx_neutral = np.where(kmeans.labels_ == neutral_label)  # 找到中性类标签的数据点索引\n",
    "        idx_happy = np.where(kmeans.labels_ == happy_label)  # 找到快乐类标签的数据点索引\n",
    "        # 初始化新的标签数组，形状与 y_cp 相同\n",
    "        Y_nnp = np.zeros(y_cp.shape[0],)\n",
    "        # 根据索引设置新的标签值\n",
    "        # 将情绪分为3类：负面情绪(-1)  中性情绪(0)  正面情绪(1)\n",
    "        Y_nnp[idx_sad] = -1  # 将悲伤类标签设为 -1\n",
    "        Y_nnp[idx_fear] = -1  # 将恐惧类标签设为 -1\n",
    "        Y_nnp[idx_neutral] = 0  # 将中性类标签设为 0\n",
    "        Y_nnp[idx_happy] = 1  # 将快乐类标签设为 1\n",
    "        # 如果需要转换，则将 y_cp 更新为新的标签\n",
    "        if convert_labels_to_nnp:\n",
    "            y_cp = Y_nnp\n",
    "            # 统计每个情绪类别的数据点数量，并打印结果\n",
    "            print('Negative(-1): %i -- neutral(0): %i -- Positive(1): %i'\n",
    "                % (np.count_nonzero(Y_nnp == -1),  # 统计恐惧类标签的数据点数量\n",
    "                    np.count_nonzero(Y_nnp == 0),   # 统计悲伤类标签的数据点数量\n",
    "                    np.count_nonzero(Y_nnp == 1)))  # 统计中性类标签的数据点数量\n",
    "        else:\n",
    "            y_cp = kmeans.labels_\n",
    "            # 统计每个情绪类别的数据点数量，并打印结果\n",
    "            print('Fear(%i): %i -- Sad(%i): %i -- Neutral(%i): %i -- Happy(%i): %i'\n",
    "                % (fear_label,    np.count_nonzero(kmeans.labels_ == fear_label),  # 统计恐惧类标签的数据点数量\n",
    "                    sad_label,      np.count_nonzero(kmeans.labels_ == sad_label),   # 统计悲伤类标签的数据点数量\n",
    "                    neutral_label,  np.count_nonzero(kmeans.labels_ == neutral_label),  # 统计中性类标签的数据点数量\n",
    "                    happy_label,    np.count_nonzero(kmeans.labels_ == happy_label)))  # 统计快乐类标签的数据点数量\n",
    "        return X_cp, y_cp, subjects, trials, sessions\n",
    "\n",
    "    def sort_centeroids(self, centeroids):\n",
    "        \"\"\"\n",
    "        计算给定中心点到四个角（右下角、左下角、左上角、右上角）的距离，\n",
    "        并返回按以下顺序排列的索引：\n",
    "        - 最靠近右下角的点的索引\n",
    "        - 最靠近左下角的点的索引\n",
    "        - 最靠近左上角的点的索引\n",
    "        - 最靠近右上角的点的索引\n",
    "        参数：\n",
    "        centeroids (ndarray): 中心点数组，形状为 (num_points, 2)，每行表示一个点的坐标 (x, y)。\n",
    "        返回：\n",
    "        tuple: 包含四个整数的元组，表示最靠近右下角、左下角、左上角和右上角的点的索引。\n",
    "        \"\"\"\n",
    "        # 初始化距离数组\n",
    "        distance_br = np.zeros(centeroids.shape[0])  # 到右下角的距离\n",
    "        distance_bl = np.zeros(centeroids.shape[0])  # 到左下角的距离\n",
    "        distance_tl = np.zeros(centeroids.shape[0])  # 到左上角的距离\n",
    "        distance_tr = np.zeros(centeroids.shape[0])  # 到右上角的距离\n",
    "        # 计算每个中心点到四个角的距离\n",
    "        for i in range(centeroids.shape[0]):\n",
    "            distance_br[i] = abs((1 - centeroids[i, 0])**2 + (-1 - centeroids[i, 1])**2)\n",
    "            distance_bl[i] = abs((-1 - centeroids[i, 0])**2 + (-1 - centeroids[i, 1])**2)\n",
    "            distance_tl[i] = abs((-1 - centeroids[i, 0])**2 + (1 - centeroids[i, 1])**2)\n",
    "            distance_tr[i] = abs((1 - centeroids[i, 0])**2 + (1 - centeroids[i, 1])**2)\n",
    "        # 找到距离四个角最近的点的索引\n",
    "        br_idx = np.argmin(distance_br)  # 最靠近右下角的点的索引\n",
    "        bl_idx = np.argmin(distance_bl)  # 最靠近左下角的点的索引\n",
    "        tl_idx = np.argmin(distance_tl)  # 最靠近左上角的点的索引\n",
    "        tr_idx = np.argmin(distance_tr)  # 最靠近右上角的点的索引\n",
    "        # 返回索引\n",
    "        return br_idx, bl_idx, tl_idx, tr_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deap_preprocessing(DatabasesPre):\n",
    "    dp = DatabasesPre\n",
    "    # 加载数据\n",
    "    x_data, y_labels, subjects, trials, sessions = dp.load_deap_data(data_path=dp.databases_root_directory)\n",
    "    # 保护原始数据\n",
    "    X_cp = np.copy(x_data)\n",
    "    y_cp = np.copy(y_labels)\n",
    "    # 基线调整, 滤波, 重采样, 通道选择\n",
    "    X_cp = dp.deap_filter(X=X_cp)\n",
    "    # 标签转换: 根据情绪价度和情绪唤醒价度将标签转换为 Fear(3) -- Sad(0) -- Neutral(1) -- Happy(2)\n",
    "    X_cp, y_cp, subjects, trials, sessions = dp.deap_label_conversion(X=X_cp, y=y_cp, subjects=subjects, trials=trials, sessions=sessions)\n",
    "    # 分割数据集\n",
    "    print(\"Splitting dataset .....\")\n",
    "    X_train, X_temp, Y_train, Y_temp = train_test_split(X_cp, y_cp, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.2, random_state=42)\n",
    "    S_train, S_temp, P_train, P_temp = train_test_split(subjects, sessions, test_size=0.2, random_state=42)\n",
    "    S_val, S_test, P_val, P_test = train_test_split(S_temp, P_temp, test_size=0.2, random_state=42)\n",
    "    # 调整session的ID, 调整 sessions 的 ID 是为了在后续分析时方便区分不同的数据集\n",
    "    S_train = S_train + 100 * 1\n",
    "    S_val = S_val + 100 * 2\n",
    "    S_test = S_test + 100 * 3\n",
    "    # 保存数据\n",
    "    print(\"Saving data ......\")\n",
    "    np.savez_compressed(\n",
    "                        file = dp.databases_out_directory + dp.dataset_name,\n",
    "                        X=X_cp,\n",
    "                        y=y_cp,\n",
    "                        subject = subjects,\n",
    "                        trial = trials,\n",
    "                        session = sessions,\n",
    "                        dataset_name = dp.dataset_name,\n",
    "                        sampling_rate = dp.sampling_rate,\n",
    "                        downsampling_rate = dp.resampling_rate,\n",
    "                        baseline_removal_window = dp.baseline_removal_window,\n",
    "                        channel_names = dp.channels_to_use,\n",
    "                        seconds_to_use = dp.seconds_to_use,\n",
    "                        window_size = dp.window_size,\n",
    "                        window_overlap = dp.window_overlap,\n",
    "                        cutoff_frequencies = dp.cutoff_frequencies,\n",
    "                        X_train=X_train, X_val=X_val, X_test=X_test,\n",
    "                        Y_train=Y_train, Y_val=Y_val, Y_test=Y_test,\n",
    "                        S_train=S_train, S_val=S_val, S_test=S_test,\n",
    "                        P_train=P_train, P_val=P_val, P_test=P_test\n",
    "                        )\n",
    "    print(f\"Saved File to {dp.databases_out_directory + dp.dataset_name}.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deap_dataset_load(filename):\n",
    "    \"\"\"\n",
    "    filename = dp.databases_out_directory + dp.dataset_name + \".npz\"\n",
    "    \"\"\"\n",
    "    # 加载DEAP数据集\n",
    "    print(\"Loading dataset ......\")\n",
    "    data = np.load(filename)\n",
    "    # 展示数据集内容\n",
    "    # print(data.files)\n",
    "    X_train = data['X_train']\n",
    "    X_val = data['X_val']\n",
    "    X_test =data['X_test']\n",
    "    Y_train = data['Y_train']\n",
    "    Y_val = data['Y_val']\n",
    "    Y_test = data['Y_test']\n",
    "    S_train = data['S_train']\n",
    "    S_val = data['S_val']\n",
    "    S_test = data['S_test']\n",
    "    P_train = data['P_train']\n",
    "    P_val = data['P_val']\n",
    "    P_test = data['P_test']\n",
    "    print(\"Loading complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个数据预处理的类\n",
    "DeapDP = DatabasesPreprocessing(config=deap_config)\n",
    "# 对 DEAP 数据集进行预处理并保存处理后的数据集\n",
    "deap_preprocessing(DatabasesPre=DeapDP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt231py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
